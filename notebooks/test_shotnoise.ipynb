{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test shotnoise in the contaminated mocks --- small scale clustering changed due to Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitsio as ft\n",
    "import numpy  as np\n",
    "import healpy as hp\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mock(object):\n",
    "    def __init__(self, featsfile, paramsfile, func='lin', sf=1207432.7901):\n",
    "        # read inputs\n",
    "        feats       = ft.read(featsfile)\n",
    "        params      = np.load(paramsfile, allow_pickle=True).item()\n",
    "        # attrs\n",
    "        self.hpix   = feats['hpind']\n",
    "        self.feats  = feats['features']\n",
    "        self.axfit     = params['ax']\n",
    "        self.xstats = params['xstats']\n",
    "        #print('Will scale the covariance by %.4f'%sf)\n",
    "        bfp_raw     = params['params'][func]\n",
    "        self.bfp    = (bfp_raw[0], sf*bfp_raw[1])\n",
    "\n",
    "        #\n",
    "        # prepare\n",
    "        self.n   = self.feats.shape[0]\n",
    "        x        = (self.feats - self.xstats[0])/self.xstats[1] # select axis\n",
    "        x_scaled = x[:, self.axfit]\n",
    "        if func == 'lin':\n",
    "            x_vector = np.column_stack([np.ones(self.n), x_scaled])\n",
    "        elif func == 'quad':\n",
    "            x_vector = np.column_stack([np.ones(self.n), x_scaled, x_scaled*x_scaled])\n",
    "        else:\n",
    "            exit(f\"func:{func} is not defined\")\n",
    "        #\n",
    "        # \n",
    "        self.x_vector = x_vector\n",
    "\n",
    "    def simulate(self, kind='truth', seed=12345):\n",
    "        if kind not in ['fixed', 'random', 'truth']:\n",
    "            exit(f\"kind : {kind} is not defined\")\n",
    "        np.random.seed(seed) # set the seed\n",
    "\n",
    "        if kind == 'truth':\n",
    "            thetas = self.bfp[0]\n",
    "        elif kind == 'fixed':\n",
    "            thetas = np.random.multivariate_normal(*self.bfp)\n",
    "        elif kind == 'random':\n",
    "            thetas = np.random.multivariate_normal(*self.bfp, size=self.n)\n",
    "        else:\n",
    "            exit(f\"kind : {kind} is not defined\")\n",
    "\n",
    "        tx       = (thetas * self.x_vector)\n",
    "        self.txs = np.sum(tx, axis=1)\n",
    "\n",
    "    def project(self, hpin, tag):\n",
    "        hpmin = hp.read_map(hpin, verbose=False)\n",
    "        fpath = '/'.join((hpin.split('/')[:-1] + [tag]))\n",
    "        mname = '_'.join((tag, 'mask',hpin.split('/')[-1]))\n",
    "        fname = '_'.join((tag, hpin.split('/')[-1]))\n",
    "        if not os.path.exists(fpath):\n",
    "            os.makedirs(fpath)\n",
    "         \n",
    "        self.ngalcont = self.txs * hpmin[self.hpix]  \n",
    "        fou = '/'.join((fpath, fname))\n",
    "        mou = '/'.join((fpath, mname))\n",
    "        \n",
    "        ngal_neg   = self.ngalcont < 0.0\n",
    "        hpix_neg   = self.hpix[ngal_neg]\n",
    "        hpix_noneg = self.hpix[~ngal_neg]\n",
    "        ngal_noneg = self.ngalcont[~ngal_neg]\n",
    "        #\n",
    "        #\n",
    "        ngalm      = np.zeros_like(hpmin)\n",
    "        ngalm[hpix_noneg] = np.random.poisson(ngal_noneg)\n",
    "        #\n",
    "        #\n",
    "        self.negm = np.zeros_like(hpmin)\n",
    "        self.negm[self.hpix]  = self.ngalcont\n",
    "        #hp.write_map(mou, negm,  fits_IDL=False, overwrite=True, dtype=np.float64)\n",
    "        #hp.write_map(fou, ngalm, fits_IDL=False, overwrite=True, dtype=np.float64)\n",
    "        #print('%s is written'%fou) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456) # set the global seed        \n",
    "seeds = np.random.randint(0, 4294967295, size=1000)        \n",
    "seeds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regp = '/Volumes/TimeMachine/data/DR7/results/regression/mult_ab/regression_log.npy'\n",
    "feats = '/Volumes/TimeMachine/data/mocks/mocks.DR7.table.fits'\n",
    "mock_i = '/Volumes/TimeMachine/data/mocks/testshotnoise/001.hp.256.fits'\n",
    "\n",
    "mymock  = mock(feats, \n",
    "               regp,\n",
    "               func='lin', sf=23765.2929*0.05) # 0.1XtotalfracXvarngal = 2376.52929\n",
    "mymock.simulate(kind='random', seed=545331265)\n",
    "mymock.project(mock_i, 'cp2ptest')\n",
    "ngal_test = mymock.negm.copy()\n",
    "\n",
    "mymock.simulate(kind='truth', seed=545331265)\n",
    "mymock.project(mock_i, 'cp2ptest')\n",
    "ngal_test_truth = mymock.negm.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngal_null = hp.read_map('/Volumes/TimeMachine/data/mocks/testshotnoise/001.hp.256.fits') \n",
    "#ngal_test = hp.read_map('/Volumes/TimeMachine/data/mocks/testshotnoise/cp2ptest/cp2ptest_001.hp.256.fits')\n",
    "ngal_org = hp.read_map('/Volumes/TimeMachine/data/mocks/testshotnoise/cp2p_001.hp.256.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = hp.read_map('/Volumes/TimeMachine/data/mocks/fracgood.hp256.fits')\n",
    "mask = hp.read_map('/Volumes/TimeMachine/data/mocks/mask.cut.w.hp.256.fits') > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlin = hp.read_map('/Volumes/TimeMachine/data/mocks/3dbox/001/results/regression/mult_all/lin-weights.hp256.fits')\n",
    "wlinc = hp.read_map('/Volumes/TimeMachine/data/mocks/3dbox/001/cp2p/results/regression/mult_all/lin-weights.hp256.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngal_null_w = ngal_null/wlin\n",
    "ngal_org_w = ngal_org/wlinc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = {'histtype':'step', 'bins':np.linspace(-30, 30, 60)}\n",
    "plt.hist(ngal_null[mask], **kw, label='Null')\n",
    "plt.hist(ngal_null_w[mask], **kw, label='Null wsys')\n",
    "plt.hist(ngal_org[mask], **kw, label='Cont after Poisson')\n",
    "plt.hist(ngal_org_w[mask], **kw, label='Cont after Poisson wsys')\n",
    "plt.hist(ngal_test[mask], **kw, label='Cont before Poisson')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Ngal [per pixel]')\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = {'histtype':'step', 'bins':np.linspace(-30, 30, 60), 'weights':1./frac[mask]}\n",
    "plt.hist(ngal_null[mask], **kw, label='Null')\n",
    "plt.hist(ngal_null_w[mask], **kw, label='Null wsys')\n",
    "plt.hist(ngal_org[mask], **kw, label='Cont after Poisson')\n",
    "plt.hist(ngal_org_w[mask], **kw, label='Cont after Poisson wsys')\n",
    "plt.hist(ngal_test[mask], **kw, label='Cont before Poisson')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Ngal [per pixel]')\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalarea = hp.nside2pixarea(256, degrees=True)*3.0462e-4*mask.sum()\n",
    "area1pix = totalarea / mask.sum()\n",
    "print(f'total area : {totalarea}, area 1 pix : {area1pix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, ngali in zip(['Null', 'Cont.', 'Cont. before Poisson'],\n",
    "                       [ngal_null, ngal_org, ngal_test]):\n",
    "    \n",
    "    print(f'{name:20s}, {np.average(ngali[mask], weights=1./frac[mask])} {np.std(ngali[mask])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssclustering(std, Nbar):\n",
    "    area1pix = 1.5979101887764102e-05\n",
    "    \n",
    "    nbar = Nbar / area1pix    # per steradians\n",
    "    sq_nbar = nbar*nbar       # per sq. steradians\n",
    "    sq_std = std*std / area1pix # per steradians\n",
    "    \n",
    "    small_scale_clustering = sq_std/sq_nbar - (1./nbar)\n",
    "    \n",
    "    print(sq_std/sq_nbar, 1./nbar, small_scale_clustering)\n",
    "    #return small_scale_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, ngali in zip(['Null', 'Cont.', 'Cont. before Poisson'],\n",
    "                       [ngal_null, ngal_org, ngal_test]):\n",
    "    \n",
    "    std = np.std(ngali[mask]/frac[mask])\n",
    "    Nbar = np.mean(ngali[mask]/frac[mask])\n",
    "    \n",
    "    print(f'{name:20s}', end=' ')\n",
    "    ssclustering(std, Nbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3.33e-7/0.10912503642658404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5.969930037105104e-06 - 2.853234291573167e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area1pix*(1/6.860573378588779+1/7.031814214075481)/ 3.0515453731283023e-06 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5.41493819699172e-06 - 2.853234291573167e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shotnoise_cont = 5.969930037105104e-06 - 5.549918401133836e-07 # sq_sig - small. scale. clustering\n",
    "shotnoise_cont_woPoisson = 3.6556365479861135e-06 - 5.549918401133836e-07 # sq_sig - small. scale. clustering\n",
    "print(shotnoise_cont, shotnoise_cont_woPoisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anafast(map1, weight1, mask1):\n",
    "    hmap1 = hp.ma(map1*weight1)\n",
    "    hmap1.mask = np.logical_not(mask1)\n",
    "    hmap1 = hmap1.filled()\n",
    "    \n",
    "    return hp.anafast(hmap1, lmax=512)/np.mean(mask1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import makedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_null = makedelta(ngal_null, frac, mask)\n",
    "d_org = makedelta(ngal_org, frac, mask)\n",
    "d_test = makedelta(ngal_test, frac, mask)\n",
    "d_test_truth = makedelta(ngal_test_truth, frac, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_null = anafast(d_null, frac, mask)\n",
    "cl_cont = anafast(d_org, frac, mask)\n",
    "cl_test = anafast(d_test, frac, mask)\n",
    "cl_truth = anafast(d_test_truth, frac, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_null_t = np.load('/Volumes/TimeMachine/data/mocks/3dbox/001/results/clustering/cl_uni.npy', allow_pickle=True).item()\n",
    "cl_cont_t = np.load('/Volumes/TimeMachine/data/mocks/3dbox/001/cp2p/results/clustering/cl_uni.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(cl_null, c='k', ls=':', lw=1, zorder=10)           \n",
    "plt.loglog(cl_cont-2.266925134457511e-06, c='k', lw=1)\n",
    "plt.loglog(cl_test, c='r', lw=2, alpha=0.8)\n",
    "plt.loglog(cl_truth, c='b', lw=1, alpha=0.6)\n",
    "plt.legend(['Null', 'Cont after Poisson', 'Cont before Poisson', 'Cont without Noise'])\n",
    "plt.ylim(1.0e-6, 1.0e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = hp.read_map('/Volumes/TimeMachine/data/mocks/fracgood.hp256.fits', verbose=False)\n",
    "mask = hp.read_map('/Volumes/TimeMachine/data/mocks/mask.cut.w.hp.256.fits', verbose=False) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shotnoise(galmap, frac, mask):\n",
    "    std = np.std(galmap[mask]/frac[mask])\n",
    "    Nbar = np.mean(galmap[mask]/frac[mask])\n",
    "    \n",
    "    area1pix = 1.5979101887764102e-05\n",
    "    \n",
    "    nbar = Nbar / area1pix    # per steradians\n",
    "    sq_nbar = nbar*nbar       # per sq. steradians\n",
    "    sq_std = std*std / area1pix # per steradians\n",
    "    \n",
    "    return sq_std/sq_nbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null = lambda i:f'/Volumes/TimeMachine/data/mocks/3dbox/{i:03d}/{i:03d}.hp.256.fits'\n",
    "cont = lambda i:f'/Volumes/TimeMachine/data/mocks/3dbox/{i:03d}/cp2p/cp2p_{i:03}.hp.256.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['null'] = np.zeros(100)\n",
    "df['cont'] = np.zeros(100)\n",
    "\n",
    "for i in range(0, 100):\n",
    "    gnull = hp.read_map(null(i+1), verbose=False)\n",
    "    gcont = hp.read_map(cont(i+1), verbose=False)\n",
    "    \n",
    "    df['null'][i] = shotnoise(gnull, frac, mask)\n",
    "    df['cont'][i] = shotnoise(gcont, frac, mask)\n",
    "    \n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cont_mult_all_lin'] = np.zeros(100)\n",
    "\n",
    "contw = lambda i:f'/Volumes/TimeMachine/data/mocks/3dbox/{i:03d}/cp2p/results/regression/mult_all/lin-weights.hp256.fits'\n",
    "\n",
    "for i in range(0, 100):\n",
    "    \n",
    "    gcont = hp.read_map(cont(i+1), verbose=False)\n",
    "    wcont = hp.read_map(contw(i+1), verbose=False)\n",
    "    \n",
    "    df['cont_mult_all_lin'][i] = shotnoise(gcont/wcont, frac, mask)\n",
    "    \n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cont_mult_all_quad'] = np.zeros(100)\n",
    "\n",
    "contw = lambda i:f'/Volumes/TimeMachine/data/mocks/3dbox/{i:03d}/cp2p/results/regression/mult_all/quad-weights.hp256.fits'\n",
    "\n",
    "for i in range(0, 100):\n",
    "    \n",
    "    gcont = hp.read_map(cont(i+1), verbose=False)\n",
    "    wcont = hp.read_map(contw(i+1), verbose=False)\n",
    "    \n",
    "    df['cont_mult_all_quad'][i] = shotnoise(gcont/wcont, frac, mask)\n",
    "    \n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cont_mult_f_lin'] = np.zeros(100)\n",
    "\n",
    "contw = lambda i:f'/Volumes/TimeMachine/data/mocks/3dbox/{i:03d}/cp2p/results/regression/mult_f/lin-weights.hp256.fits'\n",
    "\n",
    "for i in range(0, 100):\n",
    "    \n",
    "    gcont = hp.read_map(cont(i+1), verbose=False)\n",
    "    wcont = hp.read_map(contw(i+1), verbose=False)\n",
    "    \n",
    "    df['cont_mult_f_lin'][i] = shotnoise(gcont/wcont, frac, mask)\n",
    "    \n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cont_mult_f_quad'] = np.zeros(100)\n",
    "\n",
    "contw = lambda i:f'/Volumes/TimeMachine/data/mocks/3dbox/{i:03d}/cp2p/results/regression/mult_f/quad-weights.hp256.fits'\n",
    "\n",
    "for i in range(0, 100):\n",
    "    \n",
    "    gcont = hp.read_map(cont(i+1), verbose=False)\n",
    "    wcont = hp.read_map(contw(i+1), verbose=False)\n",
    "    \n",
    "    df['cont_mult_f_quad'][i] = shotnoise(gcont/wcont, frac, mask)\n",
    "    \n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cont_mult_t_lin'] = np.zeros(100)\n",
    "\n",
    "contw = lambda i:f'/Volumes/TimeMachine/data/DR7/results/regression/mult_ab/lin-weights.hp256.fits'\n",
    "\n",
    "for i in range(0, 100):\n",
    "    \n",
    "    gcont = hp.read_map(cont(i+1), verbose=False)\n",
    "    wcont = hp.read_map(contw(i+1), verbose=False)\n",
    "    \n",
    "    df['cont_mult_t_lin'][i] = shotnoise(gcont/wcont, frac, mask)\n",
    "    \n",
    "    print('.', end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cont_nn_f_nn'] = np.zeros(100)\n",
    "\n",
    "contw = lambda i:f'/Volumes/TimeMachine/data/mocks/3dbox/{i:03d}/cp2p/results/regression/nn_f/nn-weights.hp256.fits'\n",
    "\n",
    "for i in range(0, 100):\n",
    "    \n",
    "    gcont = hp.read_map(cont(i+1), verbose=False)\n",
    "    wcont = hp.read_map(contw(i+1), verbose=False)\n",
    "    \n",
    "    df['cont_nn_f_nn'][i] = shotnoise(gcont/wcont, frac, mask)\n",
    "    \n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cont_nn_p_nn'] = np.zeros(100)\n",
    "\n",
    "contw = lambda i:f'/Volumes/TimeMachine/data/mocks/3dbox/{i:03d}/cp2p/results/regression/nn_p/nn-weights.hp256.fits'\n",
    "\n",
    "for i in range(0, 100):\n",
    "    \n",
    "    gcont = hp.read_map(cont(i+1), verbose=False)\n",
    "    wcont = hp.read_map(contw(i+1), verbose=False)\n",
    "    \n",
    "    df['cont_nn_p_nn'][i] = shotnoise(gcont/wcont, frac, mask)\n",
    "    \n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cont_nn_ab_nn'] = np.zeros(100)\n",
    "\n",
    "contw = lambda i:f'/Volumes/TimeMachine/data/mocks/3dbox/{i:03d}/cp2p/results/regression/nn_ab/nn-weights.hp256.fits'\n",
    "\n",
    "for i in range(0, 100):\n",
    "    \n",
    "    gcont = hp.read_map(cont(i+1), verbose=False)\n",
    "    wcont = hp.read_map(contw(i+1), verbose=False)\n",
    "    \n",
    "    df['cont_nn_ab_nn'][i] = shotnoise(gcont/wcont, frac, mask)\n",
    "    \n",
    "    print('.', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Volumes/TimeMachine/data/mocks/shotnoises.npy', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, nrows=3, figsize=(24, 12), sharex=True, sharey=True)\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i,k in enumerate(df):\n",
    "    if k == 'null':\n",
    "        continue\n",
    "    diff = 1.0e6*(df[k] - df['null'])\n",
    "    ax[i].hist(diff, color='lightgrey')\n",
    "    ax[i].axvline(np.mean(diff), color='k')\n",
    "    \n",
    "    ax[i].tick_params(direction='in', axis='both', which='both')\n",
    "    ax[i].text(0.1, 0.9, k, transform=ax[i].transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_shotnoise = {}\n",
    "for i,k in enumerate(df):\n",
    "    \n",
    "    if k == 'null':\n",
    "        continue\n",
    "        \n",
    "    diff = (df[k] - df['null'])\n",
    "    mean_shotnoise[k] = np.mean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_shotnoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Volumes/TimeMachine/data/mocks/mean_diffshotnoises.npy', mean_shotnoise)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3p6",
   "language": "python",
   "name": "py3p6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
