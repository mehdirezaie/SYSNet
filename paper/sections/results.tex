%
%   results
%
\section{Results}\label{sec:results}
In this section, we present the measurements of the clustering statistics before and after correcting for the systematic effects for the real dataset as well as the simulated ones. We demonstrate that the neural network is capable of learning more structure in the observed galaxy density field due to its greater flexibility beyond a fixed functional form, and therefore it can eliminate more excess clustering which is believed to be due to the imaging systematics. We then show the performance of the neural network and multivariate linear models when applied to the mock datasets.

\subsection{Mitigating systematics from DR7}
\label{sec:mitigateDR7}
In the left panel of Fig. \ref{fig:weights}, we show the pixel distribution histograms of the selection masks from the three different regression models we consider in this paper. While all three models show fairly consistent selection masks for most of the pixels (note the logarithmic scaling of $Npix$), the neural network method (solid red curve) returns extended tails due to a higher representation flexibility associated with its nonlinear nature. We remove pixels with $\hat{\mathcal{F}} < 0.5$ or $> 2.0$ from our data to avoid too aggressive selection correction since we believe none of these methods can be accurate enough for such a long baseline extrapolation. These pixels account for 1.0\% of the original data (from 187,257 to 185,781 pixels). In the right panel, we show the spatial distribution of the removed pixels in the case of the neural network selection mask. \\

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{figures/fig11-weights.pdf}
    \caption{The pixel distribution  of  the  selection  masks for DR7. \textit{Left}: Distribution of the selection masks (i.e., estimates of the contamination model) derived from different regression models. \textit{Right}: Spatial scatter of the pixels we remove from our data due to the extreme values of the neural network selection mask.}
    \label{fig:weights}
\end{figure*}


Fig. \ref{fig:density_selection} illustrates the spatial distribution of the observed galaxy density before (top left) and after correction (top right) using the neural network selection mask. The bottom panels show the neural network selection mask used for the correction (left) in comparison to the masks derived from the linear (middle) and the quadratic polynomial (right) models. All three masks capture a very similar large scale pattern such as the decrease in the galaxy density close to the Galactic midplane, which is consistent with the negative correlation coefficients between the galaxy density and the Galactic extinction, hydrogen column density, or stellar density. On smaller angular scales, the three selection masks show different fluctuation details. In the following analyses, we examine which method returns the least contaminated galaxy density distribution. \\

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{figures/fig12-density_selection.pdf}
    \caption{\textit{Top}: The normalized observed galaxy density of  DR7 before and after systematics treatment using the neural network selection mask, respectively, from left to right. \textit{Bottom}: the selection masks from the Neural Network, quadratic, and linear polynomial models, respectively from left to right. All three selection masks are able to capture the behavior that the galaxy density systematically drops at the footprint boundaries i.e., high extinction regions.}
    \label{fig:density_selection}
\end{figure*}


First, once the systematic effects are corrected for, the mean galaxy density should be independent of the imaging attributes. In Fig. \ref{fig:nnbar} we show the mean number density of galaxies as a function of the imaging attributes. Again, different bins are set to include the same effective pixel area and therefore have the same sampling error. The solid black curve shows the galaxy mean density before correction and the solid red shows the result after correction with the selection mask of the neural network model. The dot-dashed curve represents the correction using the linear polynomial model and the dashed curve is for the quadratic polynomial model. The errorbars are computed using 20 Jackknife sub-samples and shown on only one case for clarity. Similar to what we found from the feature selection procedure, the stellar density, Galactic extinction, and HI density exhibit the strongest dependence before correction. After correction, all three methods return the fractional galaxy density close to unity. To quantify the deviation from unity, we report the $\chi^{2}$ statistics in Tab.~\ref{tab:chi2} while ignoring the covariance between the different bins and different imaging attributes. Overall, the neural network achieves the smallest deviation from unity which indicates its highest efficiency in reducing the systematic effects. Ideally we would like to have residual contamination less than the statistical error. Figure \ref{fig:nnbar} and Table \ref{tab:chi2} implies that we need to further improve the mitigation techniques for future cosmological analyses. In Section \ref{subsec:discussion} we provide a more detailed analysis using the same $\chi^{2}$ statistics and the mocks to quantify the remaining systematics and assess whether or not the data is clean enough.\\

\begin{table}
    \centering
    \caption[Caption]{The $\chi^{2}$ values for the measured mean density of the DR7 galaxies vs imaging systematics, presented in Fig. \ref{fig:nnbar}. This table presents the cumulative values over all bins and all imaging attributes (i.e., $N_{\rm bins}=$20 bins $\times$ 18 attributes) without accounting for the covariance both between the imaging maps and between different bins\protect\footnotemark.}
    \label{tab:chi2}
    \begin{tabular}{lccr} % four columns, alignment for each
        %\hline
        \hline
        Correction scheme & $\chi^{2}$ & $N_{\rm bins}$ & $\chi^{2}/N_{\rm bins}$ \\
        \hline
        None & 20921.633 & 360 & 58.116\\
        Linear & 2588.349 & 360 & 7.190\\
        Quadratic & 2623.006 & 360 & 7.286 \\
        Neural Network & 966.601 & 360 & 2.685\\
        %\hline
        %\hline
    \end{tabular}
\end{table}

\begin{figure*}
\centering
\includegraphics[width=0.79\textwidth]{figures/fig13-nnbardr7.pdf}
\caption{The mean number density of the DR7 galaxies as a function of the potential systematics. The solid black curve shows the result before mitigation (\textit{no correction}); the solid red curve is for the result after correcting with the neural network selection mask; the dot-dashed and dashed black curves represent mitigations with the linear and quadratic polynomial selection masks, respectively. The error bars are estimated using the Jackknife resampling of 20 non-contiguous subsamples of pixels within each imaging attribute bin (a total of 20 bins per attribute) and are shown only for one case. This plot again shows that the Galactic foregrounds such as the stellar density introduce a systematic trend in the galaxy density, which indicates a significant contamination by our own galaxy before mitigation. Such systematic trends are mostly removed with any of the three mitigation methods. \label{fig:nnbar}}
\end{figure*}


We next evaluate the performance of different mitigation techniques using the two-point statistics. We first show the cross power spectra between the DR7 observed galaxy density and various imaging attributes in the form of  $[\hat{C}^{g,s_k}_{\ell}]^2/\hat{C}^{s_k,s_k}_{\ell}$ in Fig. \ref{fig:clcross}. Again, this quantity approximately represents the level of contamination from each attribute to the auto power spectrum of galaxy density and we therefore compare this with the uncertainty in the auto as well as cross power spectrum of galaxies (light and dark gray shades) which are estimated using the Jackknife resampling of 20 equal-area contiguous regions (see Fig. \ref{fig:jackknifes}). Similarly, we plot $[\omega^{g,s_k}(\theta)]^2/\omega^{s_k,s_k}(\theta)$ in Fig.~\ref{fig:xicross} to assess the contamination in the auto-correlation function. Fig. \ref{fig:clcross} and \ref{fig:xicross} show significant contamination on large scales from $ebv$, $lnHI$, and $nstar$ compared to the statistical fluctuation estimated from the Jackknife subsampling of the data. The stellar density map shows the highest cross power spectrum with the galaxy density map, which is in agreement with the previous results. Qualitatively, all three mitigation techniques perform well and substantially reduce the cross power below $\ell \sim 30$ and over all separation scales in the cross-correlation function. The neural network method shows a slightly lower cross-power, but this appears to be merely related to the lower amplitude of the corresponding auto galaxy power spectrum compared to the other two cases. We note the spurious peak in the cross-correlation against exptime-z in Fig.~\ref{fig:xicross} near the expected angular location of the BAO feature and such feature necessitates thorough investigations of imaging systematics in analyzing the auto clustering statistics of the spectroscopic data for BAO analysis.\\

\begin{figure*}
\centering
\includegraphics[width=0.78\textwidth]{figures/fig14-dr7crosscl.pdf}
\caption{The cross power spectrum $\hat{C}^{g,s_k}_{\ell}$ between the DR7 observed galaxy density and the imaging attributes $s_k$ normalized by the auto power spectrum of the imaging attribute $\hat{C}^{s_k,s_k}_{\ell}$. The plotted quantity $[\hat{C}^{g,s_k}_{\ell}]^2/\hat{C}^{s_k,s_k}_{\ell}$ approximately represents the level of contamination to the auto power spectrum of the galaxy density $\hat{C}^{g,g}_{\ell}$. The light and dark grey shaded regions, respectively, show the Jackknife error estimate of $\hat{C}^{g,g}_{\ell}$ and $[\hat{C}^{g,s_k}_{\ell}]^2/\hat{C}^{s_k,s_k}_{\ell}$ with the galaxy density $g$ before mitigation. The black solid curve shows the result before mitigation (\textit{no correction}), while the solid red curve shows the result after correcting for the systematics with the neural network selection mask. The dot-dashed and dashed black curves show the corrected results with the linear and quadratic polynomial model selection masks, respectively. \label{fig:clcross}}
\end{figure*}

\begin{figure*}
\centering
\includegraphics[width=0.79\textwidth]{figures/fig15-dr7crossxi.pdf}
\caption{The cross correlation function $\omega^{g,s_k}(\theta)$ between the DR7 observed galaxy density and the imaging attributes $s_k$ normalized by the auto correlation function of the imaging attribute $\omega^{s_k,s_k}(\theta)$. The plotted quantity $[\omega^{g,s_k}(\theta)]^2/\omega^{s_k,s_k}(\theta)$ approximately represents the level of contamination to the auto correlation function of the galaxy density $\omega^{g,g}(\theta)$.  The grey shaded region shows the Jackknife error estimate of $\omega^{g,g}(\theta)$  before mitigation. All mitigation techniques are able to reduce the excess clustering signal which is due to the imaging systematics.  \label{fig:xicross}}
\end{figure*}


\begin{figure*}
\centering
\includegraphics[width=\textwidth]{figures/fig16-dr7clxi.pdf}
\caption{Two-point clustering statistics for DR7. \textit{Left}: the measured angular power spectrum without shot-noise subtraction. \textit{Right}: the HEALPix-based angular correlation function. Solid black curves show the measured statistics without correcting for the systematic effects (\textit{no correction}). The dashed and dot-dashed black curves show the statistics after correcting with linear and quadratic polynomial mitigation methods, respectively. The solid red curves show the results after correcting with our default neural network method. The dashed blue curves show the results mitigated with the neural network method but without the feature selection process. The errors are estimated using the Jackknife resampling with 20 contiguous sub-regions and are shown only for a few cases for clarity (see Fig. \ref{fig:jackknifes}).} \label{fig:clxi}
\end{figure*}

We finally present the effect of the imaging attributes before and after mitigation on the auto galaxy clustering statistics. In Fig. \ref{fig:clxi}, we illustrate the measured two-point clustering statistics for DR7; the measured angular power spectrum without shot-noise subtraction is shown in the left panel, and the HEALPix-based angular correlation function is shown in the right panel. The solid black curve shows the measured clustering before mitigation, while the corrected measurements using the traditional linear, quadratic polynomial, and the default neural network models are shown respectively with the black dot-dashed, black dashed, and solid red curves. In the right panel, the linear and the quadratic polynomial mitigation results are indistinguishable and overlaid.\\ 

% for table 4
\footnotetext{Note that the best fit neural network model was applied to the unseen data (i.e., the test set) unlike in the linear and quadratic polynomial models. Nevertheless the neural network method returns the smallest $\chi^{2}$, i.e., the highest efficiency.}


The comparison between the clustering before correction (solid black curves) and  after treatment (solid red, blue, dashed, and dot-dashed curves) suggests that the imaging systematics affect the clustering measurements mostly on large scales, e.g., large separation angles or small multipoles, as expected~\citep[see e.g.,][]{myers2007clustering, ross2007higher, huterer2013calibration}. We find that all of the mitigation methods are able to reduce such large scale contamination, while there still remains substantial excess clustering on large scales, mostly, with the two traditional linear multivariate methods. The neural network method is much more efficient in reducing such excess. When we investigate the effect of the survey window function on this data, we find that the window effect at $\ell$ < 50 is expected to be less than 5\% (more details presented in Appendix \ref{app:windowfunction}, see Fig. \ref{fig:Cellwindowratio}).\\

In comparison to our default neural network model, we also show the measurements mitigated with the neural network model without the feature selection process labeled as `plain' (blue dashed curves), which is very similar to the default case. In the next section, we test the mitigation methods using the mock datasets for which we know the true clustering signals. As will be demonstrated, our default neural network model with the feature selection process is chosen based on this mock test.

\subsection{Testing the mitigation methods on the mock data}
We treat the mocks as if the contamination model was unknown and apply the mitigation pipeline on the mocks as exactly used for the real dataset. After modeling the selection mask for each mock, we remove the pixels whose selection masks values are < 0.5 or > 2.0. This reduces the mock footprint size from 86,875 to 86,867 pixels. Again, the mocks do not include the redshift-space distortions.

\subsubsection{Feature selection of mock galaxies}
Fig.~\ref{fig:mockablation} shows the distribution of the imaging attributes selected by the feature selection process for all of the five partitions of the 100 null (left) and contaminated (right) mocks. For the null mocks, there is no contamination and the feature selection correctly removes most or all of the imaging attributes, as demonstrated by the sparse distribution of the points in the left panel. The imaging attributes that survived feature selection, probably due to a coincidental correlation with the galaxy density, are randomly distributed. On the other hand, the right panel shows that the feature selection procedure correctly identifies most of the input contamination attributes (marked by `*' on the y-axis) for the contaminated mocks and almost always selects $lnHI$ and $nstar$. Indeed, as shown in Fig.~\ref{fig:dr7ablation}, these two attributes were the two most significant input contamination.

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{figures/fig17-mockablation.pdf}
    \caption{Important imaging maps identified in the mocks by the feature selection procedure for the five partitions of the 100 null (left) and contaminated mocks (right). The maps used in the input contamination model were marked by `*'. The right panel shows that the feature selection procedure has identified EBV, Stellar density, skymag-g, seeing-g as important in most of the contaminated realizations whereas in the left panel, no map is consistently selected as important among all of the 100 null mocks.}
    \label{fig:mockablation}
\end{figure*}

\subsubsection{Mean mock galaxy density}
In Fig.~\ref{fig:nnbarmock} we show the number density of mock galaxies, averaged over the 100 mocks, as a function of the imaging attributes. As expected, the galaxy density of the contaminated mocks shows strong or moderate dependence on $ebv$, $nstar$, $lnHI$, $seeing-g$, $skymag-g$, $skymag-z$, $exptime-r$, $exptime-z$, $mjd-g$, and $mjd-z$ which were indeed the inputs to the contamination model. Meanwhile, the galaxy density also shows strong dependencies on $mjd-r$, $depth-r$, $depth-g$, and $depth-z$ through the correlation between these and the input contamination attributes. Looking at this result alone from a real data perspective, one would not be able to single out the underlying imaging attributes that are directly responsible for the contamination. When the inputs to the mitigation procedure include all of the input contamination maps, Fig.~\ref{fig:nnbarmock} shows that all methods effectively remove the dependence. In subsection \ref{subsec:discussion}, we discuss further how well the underlying true mean density is recovered after mitigation.

\begin{figure*}
    \centering
    \includegraphics[width=0.79\textwidth]{figures/fig18-mocksnnbar.pdf}
    \caption{The number density of the mock galaxies as a function of the potential systematics averaged over the 100 mock datasets. The grey shaded region illustrates 1$-\sigma$ dispersion in the null mocks. The dotted curve shows the mean density of the null mocks. The black solid curve shows the mean density dependence on the imaging attributes for the contaminated mocks. The solid red curve shows the mean density after correcting for the systematics with the neural network selection mask. The dashed black curve shows the corrected results with the quadratic polynomial model selection mask. The result of the linear polynomial model is almost unity, and therefore is omitted for clarity.}
    \label{fig:nnbarmock}
\end{figure*}

 
\subsubsection{Angular power spectrum of mock galaxies}

Fig. \ref{fig:deltaclmock} shows the mean angular power spectrum of the 100 null and 100 contaminated mocks in the left and right panel, respectively, in the top row. In the middle row, we illustrate the remaining bias\footnote{Due to the two-step noise introduced during contamination, the shot noise of the contaminated power spectra is increased by almost a factor of two. We estimate the total offset noise to be around $3.05\times10^{-6}$ from $\sigma^2(ngal)/\overline{n}^2$ and subtract it from the power spectrum of the contaminated mocks. The additional shot noise is mostly originated from the Poisson process we applied, i.e., precisely 1/$\overline{n}$, where $\overline{n}$ is the average number density after contamination, while an extra $\sim$ 10\% is also due to the noise we added to the contamination model.} on clustering after mitigation as an offset from the true power spectrum (i.e., the null power spectrum from the left panel\footnote{Note that we use the clustering of the null mocks before mitigation as the ground truth model since the survey window for all of the mocks before and after systematics treatment does not change.}). One can see that the contamination substantially increased power at $\ell < 50$. Since the contamination model is based on the linear polynomial model, all three fitting methods, i.e., the linear, quadratic, and neural network, are capable of reproducing the true input contamination, while they perform differently in the presence of the two layers of noise we added and the eight additional imaging attributes that are non-trivially correlated with the ten input contamination attributes. \\
\begin{figure*}
\centering
\includegraphics[width=\textwidth]{fig19-mockscell.pdf}
\caption{\textit{Top row}: The mean angular power spectrum of the 100 contaminated (null) mocks in the right (left) panel. \textit{Middle row}: The mean power spectrum subtracted by the mean of the null mocks to better visualize the remaining bias after each mitigation. The dark grey shaded region shows the 1$-\sigma$ confidence region of the mean of 100 mocks, while the light grey area shows the 1$-\sigma$ confidence region for one mock, calculated from the dispersion of 100 mocks. To account for the increased shot noise during contamination, we remove the same constant power from all contaminated/mitigated power spectra until their small scale power matches that of the null mock power spectrum. We quantify the significance of the remaining bias by calculating $\chi^2$, the sum of the squared offset weighted with the diagonal variance of the mean $C_\ell$ of null mocks over the last six bins ($\ell~\geq 12$). The middle panel on the left illustrates the neural network without feature selection (`plain') tends to remove the cosmological clustering signal. \label{fig:deltaclmock}}
\end{figure*}

In the right top and middle panel, we find all three methods effectively remove the contamination over $\ell < 100$; in detail, the linear (black dot-dashed) and the quadratic polynomial (black dashed) methods slightly over-correct power while the neural network method (solid red) slightly under-corrects it. Note that, without the feature selection process (dashed blue), the neural network method would also over-correct the large scale power like the linear and quadratic polynomial models. The left top and middle panel show that, in the absence of contamination, both the linear and quadratic polynomial methods over-correct the large scale power since the fitting methods can always find purely coincidental consistency between the imaging attributes and the cosmic variance. The quadratic method that has a greater freedom appears more prone to such problem. On the other hand, the neural network method without the feature selection process shows a lesser degree of overfitting than the linear methods, probably due to the validation procedure. Our default neural network method, which incorporates feature selection, is the most robust mitigation methodology against overfitting.\\

\begin{figure*}
\centering
\includegraphics[width=\textwidth]{figures/fig20-chi2clmock.pdf}
\caption{Dependence of $\chi^{2}$ on the lowest bin $\ell_{\rm min}$ in the null (left) and contaminated (right) mocks. To better quantify the residual bias introduced by each method, we evaluate the dependence of the bias on the lowest bin $\ell_{{\rm min}}$ that is included in the $\chi^{2}$ computation. The default neural network method performs significantly better than the conventional methods for the null mocks, mainly because the feature selection procedure successfully prevents the method from regressing out the cosmological clustering signal. For the contaminated mocks, all methods tend to perform similarly, as expected, since all mitigation methods can reproduce the input contamination model. }\label{fig:chi2clmock}
\end{figure*}


The remaining bias can be compared to the typical error expected for such data. The dark and light grey shaded regions in the middle panels indicate the 1-$\sigma$ confidence regions for the mean and the individual mock of the 100 mocks, respectively.  We quantify the significance of such remaining bias by calculating $\chi^2$, the sum of the squared offset weighted with the diagonal variance for the mean at each $\ell$ bin. Note that we use the variance from the 100 null mocks for calculating $\chi^2$ of the contaminated mocks in order to avoid an advantage of the increased variance after contamination. We find that the default neural network with $\chi^{2}=0.74$ (reduced $\chi^{2} = 0.12 $ with $dof=6$) recovers the true underlying clustering when applied to the null mocks well within $1\sigma$ C.L. of the sample variance. We estimate the significance with taking the residual systematics as one extra degree of freedom,
\begin{equation}\label{eq:chi2sigma}
 \text{max systematics} \sim \sqrt{\chi^{2}}
\end{equation}
On the other hand, the linear and quadratic models have systematic biases with more than $4\sigma$ and $7.4\sigma$ significance. When applied to the contaminated mocks, we find that the neural network method returns$\chi^2=15.3$ from six $\ell$ bins ($\ell \geq 12$), while the linear and quadratic methods, respectively, polynomial mitigation return $27.2$ and $86.9$. The difference in $\chi^2$ among the different mitigation methods is not significant compared to the $\chi^2=17,466.8$ before mitigation. While the neural network model appears to perform the best, $\chi2$ of $15.3$ (reduced $\chi^2$ of $2.6$) indicates that the residual is much more significant than the sample variance. However, for the contaminated mocks, we added substantial statistical noises, almost doubling the noise. If we use the covariance of each contaminated/mitigated case, we get $\chi^2$ of $7.7$ (reduced $\chi2$ of $1.3$) for our default case; that is our residual is at the level of the statistical noise we added in the process of contamination. These $\chi^{2}$ values can be translated to $2.8-3.9\sigma$ uncertainties in the residual systematics (see Eq. \ref{eq:chi2sigma}) which implies any particular cosmological study requires a more thorough analysis of systematics to determine an estimate of the residual systematic uncertainty for the parameters of interest.\\

Such $\chi^2$ can depend on the lower limit of $\ell$ we consider. In Fig. \ref{fig:chi2clmock}, we investigate the behavior of the remaining bias depending on $\ell_{min}$, which shows that the neural network method consistently returns a lower remaining bias for various $\ell_{\rm min}$ choices. However, for the contaminated mocks, the difference is small and we conclude that all mitigation methods perform similarly for the contaminated mocks.\\


The bottom panels of Fig.~\ref{fig:deltaclmock} compare the noise introduced by the three different mitigation processes. The right panel shows that the contamination process (solid black) introduces additional noise on large scales relative to the variance of the null mocks (the gray shade). After mitigation, the variance is reduced, which is probably related to the decrease in the large scale power, since the variance of power is proportional to the amplitude of power itself in the Gaussian limit. The quadratic method shows the smallest fractional error on large scales due to the reduced amplitude after correction. In all cases, if we calculate the fractional variance with respect to the measured $C_\ell$ (e.g., $\sigma C_{\ell, NN}/C_{\ell, NN}$ instead of  $\sigma C_{\ell, NN}/C_{\ell, Null}$), it agrees with the fractional variance of the null mock (gray shade). Therefore, we do not observe a nontrivial increase in variance by any of the mitigation methods we tested.


\subsubsection{Cross power spectrum of mock galaxies and imaging attributes}
In Fig. \ref{fig:clcrossmock}, we show the mean cross power spectrum of the 100 mock catalogs and the imaging attributes for the different mitigation techniques. All three methods substantially reduce the cross power with the imaging attributes. The neural network method tends to show a small residual for $\ell <10$ that is greater than those of the linear and quadratic polynomial models. The dark shaded region shows the 1$-\sigma$ confidence region of the mean cross power propagated to $C_{s,g}^{2}/C_{s,s}$ and the light shaded region shows the 1$\sigma$ confidence interval of the mean auto-power spectrum of the mocks as shown in Fig. \ref{fig:clcross}. Therefore, we find that these residuals are greater than the statistical noise of $C_{s,g}^{2}/C_{s,s}$, but  the effect on the \textit{auto power spectrum} are marginal for $\ell~ >~ 10$. This excess on small $\ell$ is partly due to the greater auto galaxy power spectrum amplitude (in Fig.~\ref{fig:deltaclmock}) after mitigation than those by the other methods. Meanwhile we still find a residual correlation with skymag-z and mjd-z even after accounting for the effect of the auto power spectrum amplitude. Without the feature selection procedure (dashed blue), the neural network also returns a smaller residual. In essence, we see that once feature selection is applied, the neural network only corrects to a certain level, controlled by the specifics of the feature selection procedure. This protects against over-fitting due to random correlations between the imaging attributes and the galaxy density field.\\

\begin{figure*}
\centering
\includegraphics[width=0.78\textwidth]{figures/fig21-clcrossmock.pdf}
\caption{The mean cross power spectrum of the contaminated mock catalogs and the imaging attributes for different mitigation techniques. Our default neural network method with feature selection is shown in solid red while the performance without feature selection (`Neural Network (Plain)') is shown in dashed blue. The dark grey shaded region shows the 1$\sigma$ confidence region of the plotted quantity derived from $2\sigma(C_{g,s})*C_{g,s}/C_{s,s}$, and the light grey region shows the typical 1-$\sigma$ confidence region of the mean auto power spectrum of the 100 mocks. The mitigation with the ground truth contamination model is shown with a purple dot-dashed curve as `cont. with linear (truth)'. \label{fig:clcrossmock}}
\end{figure*}

As a sanity check, if we use the true input linear contamination model to mitigate the systematics (purple dot-dashed line in Fig. \ref{fig:clcrossmock}), the cross-correlation completely vanishes as expected\footnote{The auto-power spectrum of the contaminated mocks mitigated with the true input contamination model (in Fig. \ref{fig:mockdclextra}) returns the smallest residual bias relative to the uncontaminated clustering, as expected.}. For the null mocks, all mitigation methods return negligible cross-correlation, which is omitted from Fig. \ref{fig:clcrossmock} for clarity.\\

Overall, while the cross-correlation statistics between the galaxy density and the systematics attributes are a useful indicator for the level of contamination, we find it may be difficult to infer and discriminate the level of contamination in the density field from such cross-correlation statistics beyond what can be probed by the auto power spectrum.

\subsubsection{A case with underfitting}
It is possible that we may identify only a subset of the contamination attributes for a given data set and attempt to mitigate the contamination based on such limited information. We consider a situation where we input only five imaging attributes to the mitigation procedure: four from the true contamination inputs, i.e., $EBV$, $lnHI$, $nstar$, $skymag-g$ and one that is not among the true contamination inputs, but correlated with the contamination inputs, i.e., $depth-r$. The neural network method could be more resilient to such limited information since its nonlinear activation function may allow the mitigation procedure to better utilize the correlation between different input imaging attributes. In Fig.~\ref{fig:mockdclextra}, the linear polynomial method with `few' inputs shows a lesser degree of overfitting for the null mocks, compared to the default linear case, while showing under-fitting for the contaminated mocks. This is expected as the freedom of the linear model is now limited.  The neural network method with the `few' inputs (without feature selection) returns a very similar pattern as the linear `few' case, which implies that our current default neural network method does not have an advantage over the linear model in such a case despite its greater flexibility. This underfitting case may be worth future investigation, as apparent excess clustering remains in DR7 in Fig.~\ref{fig:clxi} when any method is applied, but especially in the case of the application of multivariate linear models.

\begin{figure*}
\centering
\includegraphics[width=\textwidth]{figures/fig22-mockscellex.pdf}
\caption{Same as Fig. \ref{fig:deltaclmock} showing the mean auto power spectrum of the 100 null (left) and contaminated (right) mocks mitigated with the fewer imaging maps `few' (to demonstrate under-correction), neural network without the feature selection `plain', and the ground truth contamination model `truth'. The mitigation with the ground truth model achieves the lowest residual bias as expected. For the null mocks, using fewer imaging maps prevents over-fitting simply by providing less freedom in the regression model while it leads to underfitting for the contaminated mocks. }
\label{fig:mockdclextra}
\end{figure*}


\subsection{Summary and Discussion}\label{subsec:discussion}
In summary, we find that our default neural network method is more robust against overfitting based on the test with the null mocks. This is due to the feature selection process that appropriately reduces the flexibility of mitigation. Based on the tests with the contaminated mocks, we find that both the linear and neural network methods perform equally well in terms of the residual bias, while the neural network method is more robust against overfitting. The quadratic polynomial method appears to be more prone to the overfitting problem than the other two methods since it has a greater flexibility than the input contamination model, but without a way to suppress the flexibility. All methods do not increase fractional variance during the mitigation process. Note again that we deliberately choose the linear model in contaminating the mocks in this test in order to prevent a disadvantage in using the linear and quadratic polynomial methods.  Therefore, the decent performance of the linear method is warranted. In real data, the contamination due to observational effects can take a more complex form as implied by the difference in the mitigation results between the data and our mocks. Therefore our mock test is a conservative estimation of the comparative mitigation capability of our default neural network method. \\

While we demonstrated qualitatively and quantitatively that our fiducial neural network method is more robust than the conventional methods, for both DR7 as well as for the mocks, Fig. \ref{fig:nnbar}-\ref{fig:clcross} show non-negligible residual contamination compared to the expectations. It is not surprising that the mitigation of imaging systematic effects in the real data is more challenging than that of the linear-model based systematics in our mock tests. In this subsection we attempt to provide a quantitative evaluation of the residual systematics of DR7.\\

We quantify the residual systematics in the mean density against the 18 imaging maps using $\chi^2$ of the mean density diagnostic as in Fig. \ref{fig:nnbar} and Table \ref{tab:chi2}~\footnote{To compare these with the mock results, we limit DR7 to the mock footprint, and therefore the $\chi^2$ results are slightly different from Fig. \ref{fig:nnbar} and Table \ref{tab:chi2}. The mock footprint is smaller than the data footprint by almost a factor of two.}. The null hypothesis is that the total residual squared error of the mean density observed in the data should be consistent with the distribution of the $\chi^{2}$ statistics constructed with the null mocks. The vertical lines in Fig. \ref{fig:chi2pdf} present the $\chi^{2}$ values observed in the data for before systematics treatment (9567.1) and after treatment with linear (2066.7), quadratic (1212.0), default Neural Network (767.3), and  Neural Network plain (744.4) approaches. As a comparison, we present the distributions of the $\chi^{2}$ observed in the null mocks (solid), contaminated mocks (dashed), and contaminated mocks after neural network mitigation (dot-dashed). Fig. \ref{fig:chi2pdf} illustrates a factor of 12 improvement in terms of the residual $\chi^2$ when using the neural network. Compared to the conventional quadratic method ($\chi^2=1212$), the NN-based method makes a factor of 1.6 improvement.\\

\begin{figure}
    \centering
    \includegraphics[width=0.45\textwidth]{figures/fig23-chi2_data_on_mock.pdf}
    \caption{\textit{Left}: $\chi^{2}$ distribution for the null mocks (solid black), contaminated mocks (dashed black), and contaminated mocks with NN mitigation (dot-dashed black). The vertical dotted lines overlay the $\chi^{2}$ values for the data with the default NN (red), quadratic (purple), and linear (grey) treatments. The $\chi^{2}$ statistics before treatment is shown on the right (dark blue).}
    \label{fig:chi2pdf}
\end{figure}

The mean and standard deviation for the distribution of $\chi^{2}$  values observed in the null mocks are $487.1 \pm 4.92$, respectively. The same quantities observed in the contaminated mocks are $2819.0 \pm 29.30$, while Neural Network mitigation decreases these statistics to the mean of $472.0\pm 6.59$. We perform Welch's t-test \citep{welch1947generalization} on the $\chi^{2}$ distributions of the null mocks and the mitigated contaminated mocks, and conclude that the two distributions have identical means with $t-statistic=1.8$, $p-value=0.06$ and the neural network recovers the underlying cosmological mean target density. Note that the mean $\chi^{2}$ observed in the contaminated mocks, 2819.0, is much smaller than the value observed in the data (the blue vertical line, 9567.1). This indicates that the systematic effects rigorously simulated in the mocks are still not as strong as the systematics in the real data or the effect of the non-diagonal terms, that we ignored in the covariance, is different in the data and in the mocks.\\

We perform a hypothesis testing given the $\chi^{2}$ value observed in the data after the neural network mitigation and the distribution of $\chi^{2}$ values observed in the 100 null mocks.
If the imaging maps were independent and normal deviates, the $\chi^{2}$ values must follow a Chi-squared distribution for $dof=360$ where 360 is the total number of bins. This assumption is not necessarily satisfied given the correlation among imaging systematics, and we indeed find $\chi^{2}$ of the null mocks is better fit with $dof=487$. Therefore, we assume that the underlying $dof$ for evaluating $\chi^2$ is 487. For DR7, the $\chi^2$ decreased from 9567 before contamination to 767.3 after our NN-based mitigation. Compared to $dof=487$ we expect for the approximate truth, this is a substantial excess, being very unlikely due to random fluctuation: for example, the top 5\% of distribution with $dof=487$ is at $\chi^2 = 539.4$, which is 40\% lower than 767.3. Assuming a mere random fluctuation is bounded at this upper 5\% and the $\chi^{2}$ values of the data are consistent with that of the mocks, this offset could imply that we underestimated the covariance at least by $\sqrt{(767.3/539.4)} = 19\%$ or that our model, when applied to DR7, missed at least 19\% of the systematic effects in the target density.\\

We further investigate the contribution of each imaging map to the residual systematics in DR7. Fig. \ref{fig:chi2breakdown} presents the $\chi^{2}$ vs each imaging map after the linear (grey), quadratic (purple), neural network with feature selection (red), and neural network plain (blue) treatments. The statistics before mitigation are not shown for clarity. We also plot the 50- and 95-th percentiles of the same quantity observed in the null mocks in orange horizontal curves. Depth-g seems to be the main source of the residual systematics which is not mitigated even by the neural network-based methods. All methods also show residual systematics against skymag-g, skymag-z, and MJD-z. The standard treatments show some additional residual systematics against E(B-V), lnHI, and exptime-z. We perform further tests by masking out high extinction and low depth-g regions. We find that applying a more rigorous cut on depth-g (e.g., depth-g $> 24.95$) yields a more cleaner mean density at the expense of losing 9\% of the data. Although our objective was to avoid applying rigorous cuts on imaging and demonstrate the gain by using non-linear methods, our tests suggest that careful masking based on imaging, particularly depth-g, seems necessary for cosmological studies. \\


In summary, our results indicate that any cosmological study requires a thorough analysis of systematics to determine an estimate of the residual systematic uncertainty for the parameters of interest. In order to use this sample for a cosmological exploitation, we would need to account for 19\%  (or more, depending on the assumption on the baseline) additional systematic errors to the statistical errors in the density field level. Our analysis also suggests that additional masking, especially based on depth-g, or improving the method to deal with depth and sky background issues would be the next steps to prepare this data for cosmological analysis. We leave this for future study, as the focus of this study is to compare our non-linear, neural network method to other map-based methods.


\begin{figure}
    \centering
    \includegraphics[width=0.45\textwidth]{figures/fig24-chi2_data_on_mock_breakdown.pdf}
    \caption{The breakdown of $\chi^{2}$ values observed in the data on the mock footprint after linear (grey), quadratic (purple), neural network with feature selection (red), and neural network plain (blue) treatments. We also plot the 50- and 95-th percentiles of the same quantity observed in the null mocks in orange curves (note that $\chi^{2}(\textbf{s)}$ is not a continuous quantity). Given the 5\% threshold, we can argue that there exists known residual systematics against E(B-V), depth-g, skymag-g, skymag-z, and MJD-z.}
    \label{fig:chi2breakdown}
\end{figure}